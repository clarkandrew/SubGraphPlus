{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["MODEL_BACKEND", "FAISS_INDEX_PATH", "TOKEN_BUDGET", "MLP_MODEL_PATH"],
  "properties": {
    "MODEL_BACKEND": {
      "type": "string",
      "enum": ["mlx", "openai", "hf"],
      "description": "Model backend to use for LLM and embeddings"
    },
    "FAISS_INDEX_PATH": {
      "type": "string",
      "description": "Path to FAISS index file"
    },
    "TOKEN_BUDGET": {
      "type": "integer",
      "minimum": 1000,
      "description": "Maximum tokens for context window"
    },
    "MLP_MODEL_PATH": {
      "type": "string",
      "default": "models/mlp_pretrained.pt",
      "description": "Path to pre-trained SubgraphRAG MLP model"
    },
    "CACHE_DIR": {
      "type": "string",
      "default": "cache/",
      "description": "Directory for all cached data"
    },
    "MAX_DDE_HOPS": {
      "type": "integer",
      "default": 2,
      "description": "Maximum number of hops for DDE encoding"
    },
    "LOG_LEVEL": {
      "type": "string",
      "enum": ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
      "default": "INFO",
      "description": "Logging level"
    },
    "API_RATE_LIMIT": {
      "type": "integer",
      "default": 60,
      "description": "API rate limit in requests per minute"
    }
  }
}