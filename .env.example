# SubgraphRAG+ Environment Variables
# Copy this file to .env and modify as needed

# Neo4j Connection
# For Docker setup
NEO4J_URI=neo4j://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# For local Neo4j installation
# USE_LOCAL_NEO4J=true

# API Security
# IMPORTANT: Change this to a strong value in production
API_KEY_SECRET=your_secret_key_for_api_authentication

# Model Backend (options: openai, hf, mlx)
MODEL_BACKEND=openai

# OpenAI Configuration (required if MODEL_BACKEND=openai)
OPENAI_API_KEY=your_openai_api_key_here

# HuggingFace Configuration (for MODEL_BACKEND=hf)
# HF_MODEL=mistralai/Mistral-7B-Instruct-v0.2
# HF_MODEL_PATH=models/local_model_path

# MLX Configuration (for Apple Silicon Macs with MLX installed)
# Set USE_MLX_LLM=true to enable MLX functionality
# Requires MLX to be installed: pip install mlx
USE_MLX_LLM=false

# MLX LLM Model (required if MODEL_BACKEND=mlx or USE_MLX_LLM=true)
# Example models:
# - mlx-community/Mistral-7B-Instruct-v0.2-4bit-mlx
# - mlx-community/Llama-2-7b-chat-hf-4bit-mlx
# - mlx-community/Meta-Llama-3-8B-Instruct-4bit-mlx
MLX_LLM_MODEL=mlx-community/Mistral-7B-Instruct-v0.2-4bit-mlx

# MLX LLM Model Local Path (optional, use if model is downloaded locally)
# MLX_LLM_MODEL_PATH=models/mlx_llm

# MLX Embedding Model (required if USE_MLX_LLM=true)
# Example models:
# - mlx-community/bge-small-en-v1.5-mlx
# - mlx-community/all-MiniLM-L6-v2-mlx
# - mlx-community/sentence-transformers-all-mpnet-base-v2-mlx
MLX_EMBEDDING_MODEL=mlx-community/gte-large-en-v1.5-mlx

# MLX Embedding Model Local Path (optional, use if model is downloaded locally)
# MLX_EMBEDDING_MODEL_PATH=models/mlx_embedding

# Standard Embedding Model (MUST match MLP training model)
# This is the model that was used to train the MLP - DO NOT CHANGE
EMBEDDING_MODEL=Alibaba-NLP/gte-large-en-v1.5

# Performance Settings
# CACHE_SIZE=1000
# INGEST_BATCH_SIZE=100

# Logging
LOG_LEVEL=INFO
# DEBUG=false
# LOG_FILE=logs/app.log